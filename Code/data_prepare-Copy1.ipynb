{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Imports\n",
    "from _Setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\Marin\\OneDrive\\Documents\\Documents\\Angelo\\Important\\Homework\\R code\\train.csv\",\n",
    "                        low_memory = False)\n",
    "test_data = pd.read_csv(r\"C:\\Users\\Marin\\OneDrive\\Documents\\Documents\\Angelo\\Important\\Homework\\R code\\test.csv\", \n",
    "                       low_memory = False)\n",
    "\n",
    "submission_data = pd.read_csv(r\"C:\\Users\\Marin\\OneDrive\\Documents\\Documents\\Angelo\\Important\\Homework\\R code\\sample_submission.csv\", \n",
    "                       low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fill_by_patient(df, patient_id_col='patient'):\n",
    "    # Create a copy of the original DataFrame\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    df_imputed.loc[:, df_imputed.columns != patient_id_col] = (\n",
    "        df_imputed.groupby(patient_id_col)\n",
    "        .ffill()\n",
    "    )\n",
    "    \n",
    "    # If there are patients with no entries for a column, those columns will remain unchanged\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>time</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16426</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16426</td>\n",
       "      <td>2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>35.25</td>\n",
       "      <td>108.5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16426</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.20</td>\n",
       "      <td>113.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16426</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>112.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16426</td>\n",
       "      <td>5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>115.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  time    HR  O2Sat   Temp    SBP   MAP   DBP  Resp  EtCO2  ...  \\\n",
       "0    16426     1   NaN    NaN    NaN    NaN   NaN   NaN   NaN    NaN  ...   \n",
       "1    16426     2  78.0   99.5  35.25  108.5  84.5  69.0  12.0    NaN  ...   \n",
       "2    16426     3  80.0   99.0  36.20  113.0  87.0  73.0  12.0    NaN  ...   \n",
       "3    16426     4  79.0  100.0  36.50  112.0  83.0  68.0  12.0    NaN  ...   \n",
       "4    16426     5  73.0  100.0  36.50  115.0  80.0  64.0  11.0    NaN  ...   \n",
       "\n",
       "    WBC  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "0   NaN         NaN        NaN  57.03     1.0    0.0    1.0        -4.25   \n",
       "1  14.2         NaN        NaN  57.03     1.0    0.0    1.0        -4.25   \n",
       "2  14.2         NaN        NaN  57.03     1.0    0.0    1.0        -4.25   \n",
       "3  14.2         NaN        NaN  57.03     1.0    0.0    1.0        -4.25   \n",
       "4  14.2         NaN        NaN  57.03     1.0    0.0    1.0        -4.25   \n",
       "\n",
       "   ICULOS  SepsisLabel  \n",
       "0     1.0          0.0  \n",
       "1     2.0          0.0  \n",
       "2     3.0          0.0  \n",
       "3     4.0          0.0  \n",
       "4     5.0          0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_forward = forward_fill_by_patient(train_data)\n",
    "train_forward.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_fill_by_patient(df, patient_id_col='patient'):\n",
    "    # Create a copy of the original DataFrame\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    df_imputed.loc[:, df_imputed.columns != patient_id_col] = (\n",
    "        df_imputed.groupby(patient_id_col)\n",
    "        .bfill()\n",
    "    )\n",
    "    \n",
    "    # If there are patients with no entries for a column, those columns will remain unchanged\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>time</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16426</td>\n",
       "      <td>1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>35.25</td>\n",
       "      <td>108.5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16426</td>\n",
       "      <td>2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>35.25</td>\n",
       "      <td>108.5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16426</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.20</td>\n",
       "      <td>113.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16426</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>112.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16426</td>\n",
       "      <td>5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>115.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  time    HR  O2Sat   Temp    SBP   MAP   DBP  Resp  EtCO2  ...  \\\n",
       "0    16426     1  78.0   99.5  35.25  108.5  84.5  69.0  12.0    NaN  ...   \n",
       "1    16426     2  78.0   99.5  35.25  108.5  84.5  69.0  12.0    NaN  ...   \n",
       "2    16426     3  80.0   99.0  36.20  113.0  87.0  73.0  12.0    NaN  ...   \n",
       "3    16426     4  79.0  100.0  36.50  112.0  83.0  68.0  12.0    NaN  ...   \n",
       "4    16426     5  73.0  100.0  36.50  115.0  80.0  64.0  11.0    NaN  ...   \n",
       "\n",
       "    WBC  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "0  14.2         NaN      162.0  57.03     1.0    0.0    1.0        -4.25   \n",
       "1  14.2         NaN      162.0  57.03     1.0    0.0    1.0        -4.25   \n",
       "2  14.2         NaN      162.0  57.03     1.0    0.0    1.0        -4.25   \n",
       "3  14.2         NaN      162.0  57.03     1.0    0.0    1.0        -4.25   \n",
       "4  14.2         NaN      162.0  57.03     1.0    0.0    1.0        -4.25   \n",
       "\n",
       "   ICULOS  SepsisLabel  \n",
       "0     1.0          0.0  \n",
       "1     2.0          0.0  \n",
       "2     3.0          0.0  \n",
       "3     4.0          0.0  \n",
       "4     5.0          0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_imputed_train = backward_fill_by_patient(train_forward)\n",
    "pre_imputed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data - Missing Values:\n",
      "                   Total Missing  Percentage\n",
      "Bilirubin_direct        1012484   93.042344\n",
      "EtCO2                    975057   89.602985\n",
      "Fibrinogen               934300   85.857616\n",
      "TroponinI                891709   81.943711\n",
      "BaseExcess               693606   63.739010\n",
      "Lactate                  689402   63.352683\n",
      "SaO2                     683290   62.791020\n",
      "Alkalinephos             650928   59.817110\n",
      "Bilirubin_total          648138   59.560723\n",
      "AST                      645965   59.361035\n",
      "FiO2                     545205   50.101682\n",
      "PaCO2                    528467   48.563541\n",
      "HCO3                     528103   48.530092\n",
      "pH                       513489   47.187136\n",
      "PTT                      492396   45.248792\n",
      "Chloride                 489811   45.011243\n",
      "Unit1                    426031   39.150172\n",
      "Unit2                    426031   39.150172\n",
      "Phosphate                265449   24.393469\n",
      "DBP                      181559   16.684387\n",
      "Calcium                  104732    9.624360\n",
      "Magnesium                 95155    8.744281\n",
      "WBC                       44834    4.120026\n",
      "Platelets                 43974    4.040996\n",
      "Hgb                       42004    3.859963\n",
      "Hct                       40045    3.679940\n",
      "Creatinine                34523    3.172495\n",
      "BUN                       34066    3.130499\n",
      "Potassium                 32293    2.967569\n",
      "Glucose                   28393    2.609178\n",
      "SBP                        7543    0.693165\n",
      "Temp                       5067    0.465633\n",
      "MAP                        2053    0.188661\n",
      "Resp                       1454    0.133616\n",
      "O2Sat                       328    0.030142\n",
      "HR                          142    0.013049\n",
      "HospAdmTime                   8    0.000735\n"
     ]
    }
   ],
   "source": [
    "#Missing values after back-for imputation \n",
    "def missing_values_percentage(data, title):\n",
    "    total_missing = data.isnull().sum()  \n",
    "    percent_missing = (total_missing / len(data)) * 100  \n",
    "    missing_data = pd.DataFrame({'Total Missing': total_missing, 'Percentage': percent_missing})\n",
    "    missing_data = missing_data[missing_data['Total Missing'] > 0]  \n",
    "    \n",
    "   \n",
    "    missing_data = missing_data.sort_values(by='Percentage', ascending=False)\n",
    "    \n",
    "    print(f\"{title} - Missing Values:\\n\", missing_data)\n",
    "\n",
    "\n",
    "missing_values_percentage(pre_imputed_train, 'Train Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on backward_fill function:\n",
    "The results of this code were run outside of this notebook, though imported through the tensor_decomp_pre_knn.pkl file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using K Means Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data\n",
    "Data decomposed into train and test data using standardscaler, scaled, then recomposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling entire data set# DO NOT RUN \n",
    "\n",
    "# DONE : Track initial null indexes to be imputed\n",
    "#indices = pre_imputed_train.isna()\n",
    "\n",
    "# DONE : Creat simple imputer to fill NaN values with the mean\n",
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputed_train = pd.DataFrame(imputer.fit_transform(pre_imputed_train), columns = pre_imputed_train.columns)\n",
    "\n",
    "# TODO : Separate train/test before scaling\n",
    "#imputed_train_x_unscaled = imputed_train.drop(\"SepsisLabel\", axis = 1, inplace = False)\n",
    "#train_y = imputed_train['SepsisLabel']\n",
    "\n",
    "# DONE : Scale the variables\n",
    "#scaler = StandardScaler()\n",
    "#scaled_train_x = pd.DataFrame(scaler.fit_transform(imputed_train_x_unscaled), columns = imputed_train_x_unscaled.columns)\n",
    "\n",
    "# DONE : Put back together for full dataframe\n",
    "#scaled_train = scaled_train_x.join(train_y)\n",
    "#scaled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         HR     O2Sat      Temp       SBP       MAP       DBP      Resp  \\\n",
      "0 -0.366247  0.747819 -2.225465 -0.654227  0.108104  0.372134 -1.285029   \n",
      "1 -0.366247  0.747819 -2.225465 -0.654227  0.108104  0.372134 -1.285029   \n",
      "2 -0.251474  0.588590 -0.911340 -0.460376  0.260250  0.680747 -1.285029   \n",
      "3 -0.308860  0.907047 -0.496353 -0.503454  0.016817  0.294981 -1.285029   \n",
      "4 -0.653182  0.907047 -0.496353 -0.374220 -0.165758 -0.013631 -1.478158   \n",
      "\n",
      "          EtCO2  BaseExcess     HCO3  ...  Platelets       Age  patient  time  \\\n",
      "0  6.868005e-15    0.054560 -0.45495  ...   -0.44147 -0.299265  16426.0   1.0   \n",
      "1  6.868005e-15    0.054560 -0.45495  ...   -0.44147 -0.299265  16426.0   2.0   \n",
      "2  6.868005e-15    0.054560 -0.45495  ...   -0.44147 -0.299265  16426.0   3.0   \n",
      "3  6.868005e-15   -0.931047 -0.45495  ...   -0.44147 -0.299265  16426.0   4.0   \n",
      "4  6.868005e-15   -0.931047 -0.45495  ...   -0.44147 -0.299265  16426.0   5.0   \n",
      "\n",
      "   Gender  Unit1  Unit2  HospAdmTime  ICULOS  SepsisLabel  \n",
      "0     1.0    0.0    1.0        -4.25     1.0          0.0  \n",
      "1     1.0    0.0    1.0        -4.25     2.0          0.0  \n",
      "2     1.0    0.0    1.0        -4.25     3.0          0.0  \n",
      "3     1.0    0.0    1.0        -4.25     4.0          0.0  \n",
      "4     1.0    0.0    1.0        -4.25     5.0          0.0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "#scaling while ommiting some variables \n",
    "indices = pre_imputed_train.isna()\n",
    "\n",
    "# Create Simple Imputer to fill NaN values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed_train = pd.DataFrame(imputer.fit_transform(pre_imputed_train), columns=pre_imputed_train.columns)\n",
    "\n",
    "# Identify columns to exclude from scaling\n",
    "#exclude_cols = ['patient', 'time', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS']\n",
    "exclude_cols = ['patient', 'time', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS']\n",
    "\n",
    "# Separate columns into those to scale and those to exclude\n",
    "cols_to_scale = imputed_train.drop(columns=exclude_cols + ['SepsisLabel']).columns\n",
    "scaled_data = imputed_train[cols_to_scale]\n",
    "\n",
    "# Scale the selected columns\n",
    "scaler = StandardScaler()\n",
    "scaled_scaled_data = pd.DataFrame(scaler.fit_transform(scaled_data), columns=cols_to_scale)\n",
    "\n",
    "# Combine scaled data with excluded columns and the target variable\n",
    "scaled_train = pd.concat([scaled_scaled_data, imputed_train[exclude_cols], imputed_train['SepsisLabel']], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(scaled_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR                  0\n",
       "O2Sat               0\n",
       "Temp                0\n",
       "SBP                 0\n",
       "MAP                 0\n",
       "DBP                 0\n",
       "Resp                0\n",
       "EtCO2               0\n",
       "BaseExcess          0\n",
       "HCO3                0\n",
       "FiO2                0\n",
       "pH                  0\n",
       "PaCO2               0\n",
       "SaO2                0\n",
       "AST                 0\n",
       "BUN                 0\n",
       "Alkalinephos        0\n",
       "Calcium             0\n",
       "Chloride            0\n",
       "Creatinine          0\n",
       "Bilirubin_direct    0\n",
       "Glucose             0\n",
       "Lactate             0\n",
       "Magnesium           0\n",
       "Phosphate           0\n",
       "Potassium           0\n",
       "Bilirubin_total     0\n",
       "TroponinI           0\n",
       "Hct                 0\n",
       "Hgb                 0\n",
       "PTT                 0\n",
       "WBC                 0\n",
       "Fibrinogen          0\n",
       "Platelets           0\n",
       "Age                 0\n",
       "patient             0\n",
       "time                0\n",
       "Gender              0\n",
       "Unit1               0\n",
       "Unit2               0\n",
       "HospAdmTime         0\n",
       "ICULOS              0\n",
       "SepsisLabel         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Use KMeans clusetering \n",
    "k = 8\n",
    "k_means_class = KMeans(n_clusters= k, max_iter=300)\n",
    "\n",
    "clusters = k_means_class.fit_predict(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Impute the missing values based upon means\n",
    "for cluster in range(k):\n",
    "    cluster_indices = np.where(clusters == cluster)[0]\n",
    "    cluster_data = scaled_train.iloc[cluster_indices]\n",
    "    cluster_mean = cluster_data.mean()\n",
    "\n",
    "    for col in scaled_train.columns:\n",
    "        for index in cluster_indices:\n",
    "            if (indices.at[index, col] == True):\n",
    "                scaled_train.at[index, col] = cluster_mean[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Train Data - Missing Values:\n",
      " Empty DataFrame\n",
      "Columns: [Total Missing, Percentage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# DONE : Ensure the filtering worked\n",
    "missing_values_percentage(scaled_train, 'Scaled Train Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Experimental Iterative Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Try the experimental imputer\n",
    "# NOTE: THIS TAKES FOREVER, DON'T RUN UNLESS 100% NECESSARY\n",
    "#imputer = IterativeImputer(random_state=0)\n",
    "#train_data_imputed = imputer.fit(train_data)\n",
    "# train_data_imputed = imputer.transform(train_data)\n",
    "# train_data_imputed_df = pd.DataFrame(train_data_imputed, columns = imputer.get_feature_names_out())#, columns = imputer.get_feature_names_out())\n",
    "# train_data_imputed_df.head(5)\n",
    "# train_data_imputed_df.to_pickle(\"../Data/imputedData/iterative_imputed.pkl\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE to increase proportion of Sepsis cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 HR         O2Sat          Temp           SBP\n",
      "count  1.088197e+06  1.088197e+06  1.088197e+06  1.088197e+06\n",
      "mean  -2.022053e-08 -9.536297e-07 -2.949833e-06  5.661632e-06\n",
      "std    1.000000e+00  1.000000e+00  1.000001e+00  1.000001e+00\n",
      "min   -3.694685e+00 -2.456949e+01 -4.960314e+01 -5.328192e+00\n",
      "25%   -7.105684e-01 -3.667800e-01 -6.346818e-01 -7.188438e-01\n",
      "50%   -7.931298e-02  2.701335e-01 -8.136589e-02 -1.157515e-01\n",
      "75%    6.093293e-01  5.885903e-01  6.102790e-01  6.165749e-01\n",
      "max    7.266204e+00  9.070471e-01  1.817806e+01  7.595214e+00\n",
      "                 HR         O2Sat          Temp           SBP\n",
      "count  1.389147e+06  1.389147e+06  1.389147e+06  1.389147e+06\n",
      "mean   8.049548e-02 -1.321747e-02  8.213047e-02 -2.347937e-02\n",
      "std    1.031400e+00  1.017700e+00  1.086266e+00  1.002285e+00\n",
      "min   -3.694685e+00 -2.456949e+01 -4.960314e+01 -5.328192e+00\n",
      "25%   -6.531815e-01 -3.667800e-01 -5.793502e-01 -7.619218e-01\n",
      "50%    6.767295e-03  2.701335e-01  4.313019e-02 -1.157515e-01\n",
      "75%    7.241030e-01  6.558509e-01  7.486080e-01  6.165749e-01\n",
      "max    7.266204e+00  9.070471e-01  1.817806e+01  7.595214e+00\n"
     ]
    }
   ],
   "source": [
    "X = scaled_train.drop(columns = ['SepsisLabel'])\n",
    "y = scaled_train['SepsisLabel']\n",
    "\n",
    "\n",
    "sm = SMOTE(sampling_strategy=0.3, k_neighbors=5, random_state=100)\n",
    "X_train_syn, y_train_syn = sm.fit_resample(X, y)\n",
    "\n",
    "print(scaled_train.iloc[:, 0:4].describe())\n",
    "print(X_train_syn.iloc[:, 0:4].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.088197e+06\n",
      "mean     1.803166e-02\n",
      "std      1.330659e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: SepsisLabel, dtype: float64\n",
      "count    1.389147e+06\n",
      "mean     2.307690e-01\n",
      "std      4.213250e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: SepsisLabel, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train['SepsisLabel'].describe())\n",
    "print(y_train_syn.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged data set \n",
    "resampled_train = pd.DataFrame(X_train_syn)\n",
    "resampled_train['SepsisLabel'] = y_train_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepsisLabel\n",
      "0.0    98.196834\n",
      "1.0     1.803166\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Before smote distribution \n",
    "sepsis_inf = scaled_train['SepsisLabel'].value_counts()\n",
    "sepsis_percentages = (sepsis_inf / sepsis_inf.sum()) * 100\n",
    "print(sepsis_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepsisLabel\n",
      "0.0    76.923105\n",
      "1.0    23.076895\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# After smote distribution\n",
    "sepsis_inf2 = resampled_train['SepsisLabel'].value_counts()\n",
    "sepsis_percentages2 = (sepsis_inf2 / sepsis_inf2.sum()) * 100\n",
    "print(sepsis_percentages2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Convert to pickle\n",
    "#resampled_train.to_pickle(kmeansTrainFilePickle)\n",
    "#resampled_train.to_csv('imputed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Test Data preparation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>time</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>PTT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6560</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>124.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6560</td>\n",
       "      <td>2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>101.0</td>\n",
       "      <td>69.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6560</td>\n",
       "      <td>3</td>\n",
       "      <td>105.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>125.0</td>\n",
       "      <td>75.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6560</td>\n",
       "      <td>4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>150.0</td>\n",
       "      <td>94.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6560</td>\n",
       "      <td>5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  time     HR  O2Sat   Temp    SBP    MAP  DBP  Resp  EtCO2  ...  \\\n",
       "0     6560     1  110.0   98.0  37.67  124.0  78.00  NaN  16.0    NaN  ...   \n",
       "1     6560     2  103.0   96.0  37.67  101.0  69.67  NaN  16.0    NaN  ...   \n",
       "2     6560     3  105.0   96.0  37.67  125.0  75.67  NaN  16.0    NaN  ...   \n",
       "3     6560     4  118.0   94.0  37.67  150.0  94.67  NaN  16.0    NaN  ...   \n",
       "4     6560     5   99.0   94.0  37.50   98.0  64.00  NaN  16.0    NaN  ...   \n",
       "\n",
       "   PTT  WBC  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "0  NaN  NaN         NaN        NaN  81.64     1.0    1.0    0.0        -0.03   \n",
       "1  NaN  NaN         NaN        NaN  81.64     1.0    1.0    0.0        -0.03   \n",
       "2  NaN  NaN         NaN        NaN  81.64     1.0    1.0    0.0        -0.03   \n",
       "3  NaN  NaN         NaN        NaN  81.64     1.0    1.0    0.0        -0.03   \n",
       "4  NaN  NaN         NaN        NaN  81.64     1.0    1.0    0.0        -0.03   \n",
       "\n",
       "   ICULOS  \n",
       "0     2.0  \n",
       "1     3.0  \n",
       "2     4.0  \n",
       "3     5.0  \n",
       "4     6.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward fill \n",
    "test_data['HR'] = pd.to_numeric(test_data['HR'], errors='coerce')\n",
    "\n",
    "test_filled = forward_fill_by_patient(test_data)\n",
    "test_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>time</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>PTT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6560</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>124.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6560</td>\n",
       "      <td>2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>101.0</td>\n",
       "      <td>69.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6560</td>\n",
       "      <td>3</td>\n",
       "      <td>105.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>125.0</td>\n",
       "      <td>75.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6560</td>\n",
       "      <td>4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>150.0</td>\n",
       "      <td>94.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6560</td>\n",
       "      <td>5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  time     HR  O2Sat   Temp    SBP    MAP  DBP  Resp  EtCO2  ...  \\\n",
       "0     6560     1  110.0   98.0  37.67  124.0  78.00  NaN  16.0    NaN  ...   \n",
       "1     6560     2  103.0   96.0  37.67  101.0  69.67  NaN  16.0    NaN  ...   \n",
       "2     6560     3  105.0   96.0  37.67  125.0  75.67  NaN  16.0    NaN  ...   \n",
       "3     6560     4  118.0   94.0  37.67  150.0  94.67  NaN  16.0    NaN  ...   \n",
       "4     6560     5   99.0   94.0  37.50   98.0  64.00  NaN  16.0    NaN  ...   \n",
       "\n",
       "    PTT  WBC  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "0  25.8  7.3         NaN      127.0  81.64     1.0    1.0    0.0        -0.03   \n",
       "1  25.8  7.3         NaN      127.0  81.64     1.0    1.0    0.0        -0.03   \n",
       "2  25.8  7.3         NaN      127.0  81.64     1.0    1.0    0.0        -0.03   \n",
       "3  25.8  7.3         NaN      127.0  81.64     1.0    1.0    0.0        -0.03   \n",
       "4  25.8  7.3         NaN      127.0  81.64     1.0    1.0    0.0        -0.03   \n",
       "\n",
       "   ICULOS  \n",
       "0     2.0  \n",
       "1     3.0  \n",
       "2     4.0  \n",
       "3     5.0  \n",
       "4     6.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backward fill \n",
    "pre_imputed_test = backward_fill_by_patient(test_filled)\n",
    "pre_imputed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling ommiting some variables \n",
    "\n",
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputed_test = pd.DataFrame(imputer.fit_transform(pre_imputed_test), columns=pre_imputed_test.columns)\n",
    "\n",
    "# Identify columns to exclude from scaling\n",
    "#exclude_cols = ['patient', 'time', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS']\n",
    "\n",
    "# Separate columns into those to scale and those to exclude\n",
    "#cols_to_scale = imputed_test.drop(columns=exclude_cols).columns\n",
    "#scaled_data = imputed_test[cols_to_scale]\n",
    "\n",
    "# Scale the selected columns\n",
    "#scaler = StandardScaler()\n",
    "#scaled_scaled_data = pd.DataFrame(scaler.fit_transform(scaled_data), columns=cols_to_scale)\n",
    "\n",
    "# Combine scaled data with excluded columns\n",
    "#scaled_test = pd.concat([scaled_scaled_data, imputed_test[exclude_cols]], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "#print(scaled_test.head())\n",
    "\n",
    "# SCALING WHILE OMITING SOME VARIABLES FIXED# \n",
    "indices_test = pre_imputed_test.isna()\n",
    "\n",
    "# Create Simple Imputer to fill NaN values with the mean for test data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed_test = pd.DataFrame(imputer.fit_transform(pre_imputed_test), columns=pre_imputed_test.columns)\n",
    "\n",
    "# Separate columns into those to scale and those to exclude (no target variable in test)\n",
    "cols_to_scale_test = imputed_test.drop(columns=exclude_cols).columns\n",
    "\n",
    "# Scale the selected columns using the already-fitted scaler\n",
    "scaled_test_data = pd.DataFrame(scaler.transform(imputed_test[cols_to_scale_test]), columns=cols_to_scale_test)\n",
    "\n",
    "# Combine scaled data with excluded columns\n",
    "scaled_test = pd.concat([scaled_test_data, imputed_test[exclude_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling entire data set\n",
    "\n",
    "#indices_test = pre_imputed_test.isna()\n",
    "\n",
    "# Create Simple Imputer to fill NaN values with the mean for test data\n",
    "#imputed_test = pd.DataFrame(imputer.transform(pre_imputed_test), columns=pre_imputed_test.columns)\n",
    "\n",
    "# Separate test features (no target in test set)\n",
    "#imputed_test_x_unscaled = imputed_test  # No need to drop 'SepsisLabel' since it doesn't exist\n",
    "\n",
    "# Scale the test variables using the already-fitted scaler\n",
    "#test_scaled = scaler.transform(imputed_test_x_unscaled)\n",
    "\n",
    "# Convert to DataFrame for easy handling if needed\n",
    "#scaled_test = pd.DataFrame(test_scaled, columns=imputed_test_x_unscaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Use KMeans clusetering \n",
    "k = 8\n",
    "k_means_class = KMeans(n_clusters= k, max_iter=300)\n",
    "\n",
    "clusters = k_means_class.fit_predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Impute the missing values based upon means\n",
    "for cluster in range(k):\n",
    "    cluster_indices = np.where(clusters == cluster)[0]\n",
    "    cluster_data = scaled_test.iloc[cluster_indices]\n",
    "    cluster_mean = cluster_data.mean()\n",
    "\n",
    "    for col in scaled_test.columns:\n",
    "        for index in cluster_indices:\n",
    "            if (indices.at[index, col] == True):\n",
    "                scaled_test.at[index, col] = cluster_mean[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR                  0\n",
      "O2Sat               0\n",
      "Temp                0\n",
      "SBP                 0\n",
      "MAP                 0\n",
      "DBP                 0\n",
      "Resp                0\n",
      "EtCO2               0\n",
      "BaseExcess          0\n",
      "HCO3                0\n",
      "FiO2                0\n",
      "pH                  0\n",
      "PaCO2               0\n",
      "SaO2                0\n",
      "AST                 0\n",
      "BUN                 0\n",
      "Alkalinephos        0\n",
      "Calcium             0\n",
      "Chloride            0\n",
      "Creatinine          0\n",
      "Bilirubin_direct    0\n",
      "Glucose             0\n",
      "Lactate             0\n",
      "Magnesium           0\n",
      "Phosphate           0\n",
      "Potassium           0\n",
      "Bilirubin_total     0\n",
      "TroponinI           0\n",
      "Hct                 0\n",
      "Hgb                 0\n",
      "PTT                 0\n",
      "WBC                 0\n",
      "Fibrinogen          0\n",
      "Platelets           0\n",
      "Age                 0\n",
      "patient             0\n",
      "time                0\n",
      "Gender              0\n",
      "Unit1               0\n",
      "Unit2               0\n",
      "HospAdmTime         0\n",
      "ICULOS              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DONE : Ensure the filtering worked\n",
    "print(scaled_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE : Convert to pickle\n",
    "#scaled_test.to_pickle(kmeansTrainFilePickle)\n",
    "#scaled_test.to_csv('scaled_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Test Data:\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marin\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# simple logistic regression and predicting on test data \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix,  f1_score\n",
    "\n",
    "X_train = resampled_train.drop(columns=['SepsisLabel'])\n",
    "y_train = resampled_train['SepsisLabel']\n",
    "\n",
    "# Define features for the test set (assuming no target variable in test)\n",
    "X_test = scaled_test.drop(columns=['SepsisLabel'], errors='ignore')  # Ignore error if 'SepsisLabel' is not in test\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=100, max_iter = 500)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = logistic_model.predict(X_test)\n",
    "\n",
    "# If you have true labels for the test data, you can evaluate with confusion_matrix or classification_report\n",
    "# Uncomment and replace y_true_test with actual test labels if available\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_true_test, y_pred_test))\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_true_test, y_pred_test))\n",
    "\n",
    "# For demonstration, display predictions\n",
    "print(\"Predictions on Test Data:\\n\", y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6560_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6560_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6560_3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6560_4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6560_5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  SepsisLabel\n",
       "0  6560_1          0.0\n",
       "1  6560_2          0.0\n",
       "2  6560_3          0.0\n",
       "3  6560_4          0.0\n",
       "4  6560_5          0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  SepsisLabel\n",
      "0  6560_1          0.0\n",
      "1  6560_2          0.0\n",
      "2  6560_3          0.0\n",
      "3  6560_4          0.0\n",
      "4  6560_5          0.0\n"
     ]
    }
   ],
   "source": [
    "#replacing variable with preditions \n",
    "submission_data['SepsisLabel'] = y_pred_test\n",
    "\n",
    "# Optionally, save the modified DataFrame to a CSV file\n",
    "submission_data.to_csv('submission_data_with_predictions.csv', index=False)\n",
    "\n",
    "# Display the updated DataFrame (optional)\n",
    "print(submission_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in submission_data: 464354\n"
     ]
    }
   ],
   "source": [
    "#count number of rows \n",
    "num_rows = submission_data.shape[0]\n",
    "print(\"Number of rows in submission_data:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Training):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.97      0.88   1068575\n",
      "         1.0       0.67      0.23      0.34    320572\n",
      "\n",
      "    accuracy                           0.80   1389147\n",
      "   macro avg       0.74      0.60      0.61   1389147\n",
      "weighted avg       0.78      0.80      0.76   1389147\n",
      "\n",
      "F1 Score (Training): 0.3423065114851098\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with fixed effects and predicting on trainning data \n",
    "\n",
    "X_train = resampled_train.drop(columns=['SepsisLabel', 'patient', 'time'], errors='ignore')\n",
    "y_train = resampled_train['SepsisLabel']\n",
    "\n",
    "# Step 2: Initialize the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=100, max_iter=500)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make predictions on the training data\n",
    "y_pred_train = logistic_model.predict(X_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the training data\n",
    "#print(\"Training Predictions:\\n\", y_pred_train)\n",
    "#print(\"Confusion Matrix (Training):\\n\", confusion_matrix(y_train, y_pred_train))\n",
    "print(\"\\nClassification Report (Training):\\n\", classification_report(y_train, y_pred_train))\n",
    "f1 = f1_score(y_train, y_pred_train)\n",
    "print(\"F1 Score (Training):\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Apply PCA\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \n\u001b[1;32m---> 14\u001b[0m pca_data \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Check the explained variance ratio\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:474\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:511\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X_train = pre_imputed_train.drop(columns=['SepsisLabel','HospAdmTime','ICULOS'])  \n",
    "\n",
    "# Apply PCA\n",
    "\n",
    "pca = PCA(n_components=None) \n",
    "\n",
    "pca_data = pca.fit_transform(X_train)\n",
    "\n",
    "# Check the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Total explained variance by all components\n",
    "\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
